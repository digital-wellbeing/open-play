---
title: Clean raw data and save outputs
---

```{r}
library(data.table)
library(dtplyr)
library(fs)
library(tidyverse)

# Load custom functions
source("R/helpers.R")
```

```{r}
#| label: load-data-raw

intake <- read_csv("data/raw/survey_intake_raw.csv.gz")
daily <- read_csv("data/raw/survey_daily_raw.csv.gz")
biweekly <- read_csv("data/raw/survey_biweekly_raw.csv.gz")

nintendo <- read_csv("data/raw/telemetry_nintendo_raw.csv.gz")
steam <- read_csv("data/raw/telemetry_steam_raw.csv.gz")
xbox <- read_csv("data/raw/telemetry_xbox_raw.csv.gz")
ios <- read_csv("data/raw/telemetry_ios_raw.csv.gz")
android <- read_csv("data/raw/telemetry_android_raw.csv.gz")

dat_cog <- read_csv("data/raw/cognitive_tasks_raw.csv.gz")
```

```{r}
#| label: preprocess-steam

# non- and idle games lists are in helpers.R

# Arrange data to calculate differences correctly
steam_clean <- steam |>
  filter(!title_id %in% idle_games & !title_id %in% non_games) |>
  mutate(
    steam_id = as.character(steam_id),
    pid = as.character(pid)
  ) |>
  arrange(pid, title_id, timestamp) |>
  group_by(pid, steam_id) |>
  mutate(
    # Calculate time difference between consecutive polls for the same user/game
    time_diff_hours = as.numeric(difftime(
      timestamp,
      lag(timestamp),
      units = "hours"
    )),
    # Calculate playtime difference
    playtime_diff = playtime_forever - lag(playtime_forever)
  ) |>
  ungroup() |>
  # Filter out invalid calculations:
  # - First entry for each user/game (lag is NA)
  # - Negative playtime difference (data anomaly or reset?)
  # - Large time gaps between polls (e.g., > 2 hours for hourly polling, indicates missed polls or stopped tracking)
  filter(
    !is.na(playtime_diff),
    playtime_diff >= 0,
    !is.na(time_diff_hours),
    time_diff_hours > 0,
    time_diff_hours < 2 # Assuming roughly hourly polls
  ) |>
  # If playtime_diff is large, it might span multiple hours.
  # This calculation assumes playtime is evenly distributed over the polling interval.
  # A more complex approach might be needed for precise hourly allocation if intervals vary widely.
  # For simplicity here, we assign the entire playtime_diff to the hour the poll *ended*.
  mutate(
    minutes = playtime_diff,
    date = as.Date(timestamp),
    hour = hour(timestamp),
    datetime_hour_start = ymd_hms(
      paste0(date, " ", sprintf("%02d", hour), ":00:00"),
      tz = "UTC"
    )
  ) |>
  # filter out rows where 3+ games are being played simultaneously
  group_by(pid, datetime_hour_start) |>
  mutate(concurrent_titles = n_distinct(steam_id[minutes > 0])) |>
  ungroup() |>
  mutate(minutes = ifelse(concurrent_titles >= 3, 0, minutes)) |>
  group_by(pid, steam_id) |>
  # Calculate difference from previous hour and identify new sessions
  mutate(
    hour_diff = as.numeric(difftime(
      datetime_hour_start,
      lag(datetime_hour_start),
      units = "hours"
    )),
    is_new_session = ifelse(is.na(hour_diff) | hour_diff > 1, 1, 0),
    session_group_id = cumsum(is_new_session),
    session_start = datetime_hour_start,
    session_end = datetime_hour_start + hours(1) # Session ends at the end of the last hour block played
  ) |>
  filter(minutes > 0 & minutes < 120) |>
  ungroup()

```

```{r}
#| label: preprocess-xbox

# Clean Xbox data and keep only active gaming sessions
# In particular, canonicalize overlapping Xbox sessions per pid:
# - at most one title at any instant
# - handoff tolerance 'tol_sec' (short overlaps => later-starting title wins)
# - â‰¥3 concurrent titles => drop that slice

xbox_clean <- xbox |>
  filter(title_placement == "Full") |>
  filter(genres != "Video") |>
  filter(
    !is.na(session_start),
    !is.na(session_end),
    session_end > session_start
  ) |>
  filter(title_id != "e1924c10-9c91-4652-81b9-8ca0670e77a7") |> # something weird with this title, almost every player has played it and it accounts for 4x the playtime of the next-highest game - and it's unrated. I suspect it's the home screen or something.
  filter(duration <= 600) |>
  arrange(pid, session_start, session_end) |>
  canonicalize_xbox_sessions(tol_sec = 60)
```

```{r}
#| label: preprocess-nintendo

tol <- dseconds(60)

nintendo_clean <- lazy_dt(nintendo, immutable = TRUE) |>
  filter(
    !is.na(session_start),
    !is.na(session_end),
    session_end > session_start,
    session_start < time_of_pull
  ) |>
  arrange(pid, title_id, session_start, session_end) |>
  group_by(pid, title_id) |> 
  mutate(
    start_num = as.numeric(session_start),
    end_num = as.numeric(session_end),
    prev_max_end = lag(cummax(end_num), default = -Inf),
    new_cluster = start_num > (prev_max_end + as.numeric(tol)),
    cluster = cumsum(new_cluster),
    dur_sec = end_num - start_num
  ) |> 
  group_by(pid, title_id, cluster) |>
  slice_max(n = 1, order_by = dur_sec, with_ties = FALSE) |>
  ungroup() |> 
  mutate(duration = dur_sec / 60) |> 
  select(pid, title_id, session_start, session_end, duration, device_type, operation_mode) |>
  filter(duration <= 600) |>
  as_tibble()
```

```{r}
#| label: preprocess-simon

# Only include non-pilot-study participants who qualified at intake
dat_cog <- dat_cog |>
  filter(
    pid %in%
      unique(intake$pid[intake$qualified & intake$cohort != "Platform Pilot"])
  )

# Take relevant variables and observations only
# `score_final` is automatically added to all rows so distinct works here
dat_cog <- dat_cog |>
  filter(practice == 0, task == "simon") |>
  add_count(pid, wave, name = "n_trials") |>
  distinct(
    pid,
    wave,
    datetime,
    device_type,
    n_trials,
    score_final,
    meanrt_final
  )

dat_cog <- dat_cog |>
  mutate(wave = factor(wave)) |>
  arrange(wave, pid)
```

```{r}
#| label: preprocess-android

android <- android |> 
  mutate(platform = "Android") |> 
  select(pid, platform, day_local = date, minutes = total_gaming_minutes)

```

```{r}
#| label: preprocess-ios

ios <- ios |> 
  mutate(platform = "iOS") |> 
  select(pid, platform, day_local = date, minutes = total_gaming_minutes)

```

```{r}
#| label: preprocess-surveys

daily <- daily |> 
  filter(wave <= 30)

```


## Write clean data files

```{r}
#| label: write-clean-files

# Construct path and directory
path_out <- path("data", "clean")
dir_create(path_out)

# Write files
write_csv(intake, path(path_out, "survey_intake", ext = "csv.gz"))
write_csv(daily, path(path_out, "survey_daily", ext = "csv.gz"))
write_csv(biweekly, path(path_out, "survey_biweekly", ext = "csv.gz"))
write_csv(nintendo_clean, path(path_out, "nintendo", ext = "csv.gz"))
write_csv(steam_clean, path(path_out, "steam", ext = "csv.gz"))
write_csv(xbox_clean, path(path_out, "xbox", ext = "csv.gz"))
write_csv(ios, path(path_out, "ios", ext = "csv.gz"))
write_csv(android, path(path_out, "android", ext = "csv.gz"))
write_csv(dat_cog, path(path_out, "simon", ext = "csv.gz"))
```
