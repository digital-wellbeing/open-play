{
  "hash": "0702db46f8e45530861e2161a36b1888",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Clean raw data and save outputs\n---\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(data.table)\nlibrary(dtplyr)\nlibrary(fs)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.1     ✔ stringr   1.5.2\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::between()     masks data.table::between()\n✖ dplyr::filter()      masks stats::filter()\n✖ dplyr::first()       masks data.table::first()\n✖ lubridate::hour()    masks data.table::hour()\n✖ lubridate::isoweek() masks data.table::isoweek()\n✖ dplyr::lag()         masks stats::lag()\n✖ dplyr::last()        masks data.table::last()\n✖ lubridate::mday()    masks data.table::mday()\n✖ lubridate::minute()  masks data.table::minute()\n✖ lubridate::month()   masks data.table::month()\n✖ lubridate::quarter() masks data.table::quarter()\n✖ lubridate::second()  masks data.table::second()\n✖ purrr::transpose()   masks data.table::transpose()\n✖ lubridate::wday()    masks data.table::wday()\n✖ lubridate::week()    masks data.table::week()\n✖ lubridate::yday()    masks data.table::yday()\n✖ lubridate::year()    masks data.table::year()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\n# Load custom functions\nsource(\"R/helpers.R\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nintake <- read_csv(\"data/raw/survey_intake_raw.csv.gz\", guess_max = 34000)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 34643 Columns: 88\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (60): pid, country, geo_area, panel_source, cohort, local_timezone, gen...\ndbl  (19): survey_duration, diaries_completed, panels_completed, age, height...\nlgl   (7): qualified, plays_xbox, plays_steam, plays_nintendo, plays_ios, pl...\ndttm  (2): date, nintendo_account_creation_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\ndaily <- read_csv(\"data/raw/survey_daily_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 18829 Columns: 46\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (27): pid, played24hr, social_gaming_4, social_gaming_5, social_gaming_...\ndbl  (17): wave, survey_duration, bangs_1, bangs_2, bangs_3, bangs_4, bangs_...\nlgl   (1): bpnsfs_failed_att_check\ndttm  (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nbiweekly <- read_csv(\"data/raw/survey_biweekly_raw.csv.gz\", guess_max = 5000)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 7038 Columns: 158\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (57): pid, bangs_dup_item, positives, problematic_play, gdt_1, gdt_2, g...\ndbl  (74): wave, survey_duration, affective_valence, life_sat, self_reported...\nlgl  (16): bangs_failed_att_check, bfi_2_xs_1, bfi_2_xs_2, bfi_2_xs_3, bfi_2...\ndttm  (1): date\ndate  (3): recent_session1_date, recent_session2_date, recent_session3_date\ntime  (7): mctq_wd_bedtime, mctq_wd_sleep_onset_time, mctq_wd_wake_time, mct...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nnintendo <- read_csv(\"data/raw/telemetry_nintendo_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 756519 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (6): pid, title_id, operation_mode, device_type, genre, game_ref\ndbl  (2): duration, duration_nintendo\ndttm (3): session_start, session_end, time_of_pull\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nsteam <- read_csv(\"data/raw/telemetry_steam_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 1046589 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): pid, title_id, game_ref\ndbl  (4): hour, steam_id, playtime_forever, playtime_2weeks\ndttm (1): timestamp\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nxbox <- read_csv(\"data/raw/telemetry_xbox_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 4903834 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (11): pid, title_id, title_placement, publisher_id, gameplay_type, genr...\ndbl   (1): duration\ndttm  (3): session_start, session_end, time_of_pull\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nios <- read_csv(\"data/raw/telemetry_ios_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 3633 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): pid\ndbl  (1): total_gaming_minutes\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nandroid <- read_csv(\"data/raw/telemetry_android_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 2576 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): pid\ndbl  (1): total_gaming_minutes\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\ntimeuse <- read_csv(\"data/raw/timeuse_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 183280 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): pid, activity, activity_other\ndbl  (1): daily_wave\ndttm (2): start_time, end_time\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\ndat_cog <- read_csv(\"data/raw/cognitive_tasks_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 247756 Columns: 38\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (7): pid, task, device_type, stim, location, resp1, resp2\ndbl  (21): wave, rt, trial_index, time_elapsed, block_trial_count, practice,...\nlgl   (9): response, timeout, success, failed_images, failed_audio, failed_v...\ndttm  (1): datetime\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# non- and idle games lists are in helpers.R\n\n# Arrange data to calculate differences correctly\nsteam_clean <- steam |>\n  filter(!title_id %in% idle_games & !title_id %in% non_games) |>\n  mutate(\n    steam_id = as.character(steam_id),\n    pid = as.character(pid)\n  ) |>\n  arrange(pid, title_id, timestamp) |>\n  group_by(pid, steam_id) |>\n  mutate(\n    # Calculate time difference between consecutive polls for the same user/game\n    time_diff_hours = as.numeric(difftime(\n      timestamp,\n      lag(timestamp),\n      units = \"hours\"\n    )),\n    # Calculate playtime difference\n    playtime_diff = playtime_forever - lag(playtime_forever)\n  ) |>\n  ungroup() |>\n  # Filter out invalid calculations:\n  # - First entry for each user/game (lag is NA)\n  # - Negative playtime difference (data anomaly or reset?)\n  # - Large time gaps between polls (e.g., > 2 hours for hourly polling, indicates missed polls or stopped tracking)\n  filter(\n    !is.na(playtime_diff),\n    playtime_diff >= 0,\n    !is.na(time_diff_hours),\n    time_diff_hours > 0,\n    time_diff_hours < 2 # Assuming roughly hourly polls\n  ) |>\n  # If playtime_diff is large, it might span multiple hours.\n  # This calculation assumes playtime is evenly distributed over the polling interval.\n  # A more complex approach might be needed for precise hourly allocation if intervals vary widely.\n  # For simplicity here, we assign the entire playtime_diff to the hour the poll *ended*.\n  mutate(\n    minutes = playtime_diff,\n    date = as.Date(timestamp),\n    hour = hour(timestamp),\n    datetime_hour_start = ymd_hms(\n      paste0(date, \" \", sprintf(\"%02d\", hour), \":00:00\"),\n      tz = \"UTC\"\n    )\n  ) |>\n  # filter out rows where 3+ games are being played simultaneously\n  group_by(pid, datetime_hour_start) |>\n  mutate(concurrent_titles = n_distinct(steam_id[minutes > 0])) |>\n  ungroup() |>\n  mutate(minutes = ifelse(concurrent_titles >= 3, 0, minutes)) |>\n  group_by(pid, steam_id) |>\n  # Calculate difference from previous hour and identify new sessions\n  mutate(\n    hour_diff = as.numeric(difftime(\n      datetime_hour_start,\n      lag(datetime_hour_start),\n      units = \"hours\"\n    )),\n    is_new_session = ifelse(is.na(hour_diff) | hour_diff > 1, 1, 0),\n    session_group_id = cumsum(is_new_session),\n    session_start = datetime_hour_start,\n    session_end = datetime_hour_start + hours(1), # Session ends at the end of the last hour block played\n    hour_start = floor_date(timestamp, \"hour\")\n  ) |>\n  filter(minutes > 0 & minutes < 120) |>\n  ungroup()\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Clean Xbox data and keep only active gaming sessions\n# In particular, canonicalize overlapping Xbox sessions per pid:\n# - at most one title at any instant\n# - handoff tolerance 'tol_sec' (short overlaps => later-starting title wins)\n# - ≥3 concurrent titles => drop that slice\n\nxbox_clean <- xbox |>\n  filter(title_placement == \"Full\") |>\n  filter(!genres %in% c(\"Shopping\", \"Video\", \"Entertainment\", \"Utilities & tools\")) |>\n  filter(\n    !is.na(session_start),\n    !is.na(session_end),\n    session_end > session_start\n  ) |>\n  mutate(title_id = tolower(title_id)) |> \n  filter(title_id != \"e1924c10-9c91-4652-81b9-8ca0670e77a7\") |> # home screen\n  filter(duration <= 480) |>\n  arrange(pid, session_start, session_end) |>\n  canonicalize_xbox_sessions(tol_sec = 60)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntol <- dseconds(60)\n\nnintendo_clean <- lazy_dt(nintendo, immutable = TRUE) |>\n  filter(\n    !is.na(session_start),\n    !is.na(session_end),\n    session_end > session_start,\n    session_start < time_of_pull\n  ) |>\n  arrange(pid, title_id, session_start, session_end) |>\n  group_by(pid, title_id) |> \n  mutate(\n    start_num = as.numeric(session_start),\n    end_num = as.numeric(session_end),\n    prev_max_end = lag(cummax(end_num), default = -Inf),\n    new_cluster = start_num > (prev_max_end + as.numeric(tol)),\n    cluster = cumsum(new_cluster),\n    dur_sec = end_num - start_num\n  ) |> \n  group_by(pid, title_id, cluster) |>\n  slice_max(n = 1, order_by = dur_sec, with_ties = FALSE) |>\n  ungroup() |>\n  mutate(duration = dur_sec / 60) |> \n  select(pid, title_id, session_start, session_end, duration, device_type, operation_mode) |>\n  filter(duration <= 480) |>\n  as_tibble()\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Only include non-pilot-study participants who qualified at intake\ndat_cog <- dat_cog |>\n  filter(\n    pid %in%\n      unique(intake$pid[intake$qualified & intake$cohort != \"Platform Pilot\"])\n  )\n\n# Take relevant variables and observations only\n# `score_final` is automatically added to all rows so distinct works here\ndat_cog <- dat_cog |>\n  filter(practice == 0, task == \"simon\") |>\n  add_count(pid, wave, name = \"n_trials\") |>\n  distinct(\n    pid,\n    wave,\n    datetime,\n    device_type,\n    n_trials,\n    score_final,\n    meanrt_final\n  )\n\ndat_cog <- dat_cog |>\n  mutate(wave = factor(wave)) |>\n  arrange(wave, pid)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nandroid <- android |> \n  mutate(platform = \"Android\") |> \n  select(pid, platform, day_local = date, minutes = total_gaming_minutes)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nios <- ios |> \n  mutate(platform = \"iOS\") |> \n  select(pid, platform, day_local = date, minutes = total_gaming_minutes)\n```\n:::\n\n\nAs preregistered, we exclude days where total gaming time (across all platforms) exceeds 16 hours, as well as sessions that are more than 8 hours long or whose end time precedes their start time. The exclusions are applied to all relevant datasets.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# --- Build tz map (as in your script) ---------------------------------------\ntz_map <- intake |>\n  mutate(\n    pid = as.character(pid),\n    off = offset_secs(local_timezone),\n    .keep = \"none\"\n  ) |>\n  distinct(pid, .keep_all = TRUE)\n\n# --- Hourly from sessions (Nintendo + Xbox) ---------------------------------\nsessions_telemetry <- bind_rows(\n  xbox_clean |> mutate(platform = \"Xbox\"),\n  nintendo_clean |> mutate(platform = \"Nintendo\")\n) |>\n  mutate(pid = as.character(pid)) |>\n  left_join(tz_map, by = \"pid\") |>\n  mutate(\n    start_local = session_start + off,\n    end_local   = session_end   + off,\n    duration_min = as.numeric(difftime(session_end, session_start, units = \"mins\"))\n  ) |>\n  filter(\n    !is.na(session_start), !is.na(session_end),\n    session_end > session_start,\n    duration_min >= 1\n  )\n\nhourly_from_sessions <- sessions_telemetry |>\n  filter(!is.na(off)) |>\n  mutate(\n    h0_local = floor_date(start_local, \"hour\"),\n    h1_local = floor_date(end_local - seconds(1), \"hour\"),\n    n_hours = as.integer(difftime(h1_local, h0_local, units = \"hours\")) + 1\n  ) |>\n  tidyr::uncount(n_hours, .remove = FALSE, .id = \"k\") |>\n  mutate(\n    hour_start_local = h0_local + hours(k - 1),\n    minutes = pmax(\n      0,\n      as.numeric(difftime(\n        pmin(end_local, hour_start_local + hours(1)),\n        pmax(start_local, hour_start_local),\n        units = \"mins\"\n      ))\n    ),\n    hour_start_utc = hour_start_local - off\n  ) |>\n  select(pid, platform, hour_start_local, hour_start_utc, minutes)\n\n# --- Hourly from Steam (already hourly) -------------------------------------\nhourly_from_steam <- steam_clean |>\n  select(pid, datetime_hour_start, minutes) |>\n  mutate(pid = as.character(pid)) |>\n  left_join(tz_map, by = \"pid\") |>\n  mutate(\n    platform = \"Steam\",\n    hour_start_utc   = datetime_hour_start,\n    hour_start_local = datetime_hour_start + off\n  ) |>\n  select(pid, platform, hour_start_local, hour_start_utc, minutes)\n\nhourly_telemetry <- bind_rows(hourly_from_sessions, hourly_from_steam)\n\n# --- Daily totals (local day) incl. iOS/Android ------------------------------\ndaily_telemetry <- hourly_telemetry |>\n  mutate(day_local = as.Date(hour_start_local)) |>\n  group_by(pid, platform, day_local) |>\n  summarise(minutes = sum(minutes, na.rm = TRUE), .groups = \"drop\")\n\ndaily_ios_android <- bind_rows(\n  ios     |> transmute(pid = as.character(pid), platform = \"iOS\",     day_local = as.Date(day_local), minutes),\n  android |> transmute(pid = as.character(pid), platform = \"Android\", day_local = as.Date(day_local), minutes)\n)\n\ndaily_all <- bind_rows(daily_telemetry, daily_ios_android) |>\n  group_by(pid, day_local) |>\n  summarise(total_minutes = sum(minutes, na.rm = TRUE), .groups = \"drop\")\n\nexclusion_days <- daily_all |>\n  filter(total_minutes > 16 * 60) |>\n  select(pid, day_local)\n\n# --- Apply exclusions back to each dataset ----------------------------------\nsteam_clean <- steam_clean |>\n  left_join(tz_map, by = c(\"pid\" = \"pid\")) |>\n  mutate(day_local = as.Date(datetime_hour_start + off)) |>\n  anti_join(exclusion_days, by = c(\"pid\", \"day_local\")) |>\n  select(-off, -day_local)\n\nxbox_clean <- xbox_clean |>\n  left_join(tz_map, by = \"pid\") |>\n  mutate(day_local = as.Date(session_start + off)) |>\n  anti_join(exclusion_days, by = c(\"pid\", \"day_local\")) |>\n  select(-off, -day_local)\n\nnintendo_clean <- nintendo_clean |>\n  left_join(tz_map, by = \"pid\") |>\n  mutate(day_local = as.Date(session_start + off)) |>\n  anti_join(exclusion_days, by = c(\"pid\", \"day_local\")) |>\n  select(-off, -day_local)\n\nios <- ios |>\n  mutate(pid = as.character(pid), day_local = as.Date(day_local)) |>\n  anti_join(exclusion_days, by = c(\"pid\", \"day_local\"))\n\nandroid <- android |>\n  mutate(pid = as.character(pid), day_local = as.Date(day_local)) |>\n  anti_join(exclusion_days, by = c(\"pid\", \"day_local\"))\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndaily <- daily |> \n  filter(wave <= 30)\n```\n:::\n\n\n## Write clean data files\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Construct path and directory\npath_out <- path(\"data\", \"clean\")\ndir_create(path_out)\n\n# Write files\nwrite_csv(intake, path(path_out, \"survey_intake\", ext = \"csv.gz\"))\nwrite_csv(daily, path(path_out, \"survey_daily\", ext = \"csv.gz\"))\nwrite_csv(biweekly, path(path_out, \"survey_biweekly\", ext = \"csv.gz\"))\nwrite_csv(nintendo_clean, path(path_out, \"nintendo\", ext = \"csv.gz\"))\nwrite_csv(steam_clean, path(path_out, \"steam\", ext = \"csv.gz\"))\nwrite_csv(xbox_clean, path(path_out, \"xbox\", ext = \"csv.gz\"))\nwrite_csv(ios, path(path_out, \"ios\", ext = \"csv.gz\"))\nwrite_csv(android, path(path_out, \"android\", ext = \"csv.gz\"))\nwrite_csv(dat_cog, path(path_out, \"simon\", ext = \"csv.gz\"))\nwrite_csv(timeuse, path(path_out, \"timeuse\", ext = \"csv.gz\"))\n```\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}