{
  "hash": "f6bfd62e117462894c5e33b682cf48ab",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Clean raw data and save outputs\n---\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(data.table)\nlibrary(dtplyr)\nlibrary(tidycensus)\nlibrary(fs)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.1     ✔ stringr   1.5.2\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::between()     masks data.table::between()\n✖ dplyr::filter()      masks stats::filter()\n✖ dplyr::first()       masks data.table::first()\n✖ lubridate::hour()    masks data.table::hour()\n✖ lubridate::isoweek() masks data.table::isoweek()\n✖ dplyr::lag()         masks stats::lag()\n✖ dplyr::last()        masks data.table::last()\n✖ lubridate::mday()    masks data.table::mday()\n✖ lubridate::minute()  masks data.table::minute()\n✖ lubridate::month()   masks data.table::month()\n✖ lubridate::quarter() masks data.table::quarter()\n✖ lubridate::second()  masks data.table::second()\n✖ purrr::transpose()   masks data.table::transpose()\n✖ lubridate::wday()    masks data.table::wday()\n✖ lubridate::week()    masks data.table::week()\n✖ lubridate::yday()    masks data.table::yday()\n✖ lubridate::year()    masks data.table::year()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\n# Load custom functions\nsource(\"R/helpers.R\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nintake <- read_csv(\"data/raw/survey_intake_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNew names:\n• `phoneType...72` -> `phoneType...268`\n• `phoneType...115` -> `phoneType...300`\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 34206 Columns: 310\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (164): pid, status, cohort, country, used_platforms, eligible_platforms...\ndbl   (65): panels_completed, diaries_completed, total_recent_play_accounted...\nlgl   (76): plays_xbox, plays_steam, plays_nintendo, plays_ios, plays_androi...\ndttm   (5): enrollment_date, StartDate, EndDate, Q_RelevantIDLastStartDate, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\ndiary <- read_csv(\"data/raw/survey_diary_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 18829 Columns: 83\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (41): pid, bpnsfs_dup_item, played24hr, socialGaming_4, socialGaming_5,...\ndbl  (40): wave, survey_duration, bpnsfs_1, bpnsfs_2, bpnsfs_3, bpnsfs_4, bp...\nlgl   (1): bpnsfs_failed_att_check\ndttm  (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\npanel <- read_csv(\"data/raw/survey_panel_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 7038 Columns: 159\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (54): pid, cohort, bangs_dup_item, positives, problematicPlay, gdt_1, g...\ndbl  (76): wave, survey_duration, bangs_1, bangs_2, bangs_3, bangs_4, bangs_...\nlgl  (16): bangs_failed_att_check, BFI-2-XS_1, BFI-2-XS_2, BFI-2-XS_3, BFI-2...\ndttm  (1): date\ndate  (3): recentSessions_1_1, recentSessions_2_1, recentSessions_3_1\ntime  (9): mctq_3_1, mctq_3_3, mctq_3_5, mctq_6_1, mctq_6_3, mctq_6_5, recen...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nnintendo <- read_csv(\"data/raw/telemetry_nintendo_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 768299 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (5): pid, title_id, device_type, genre, game_ref\ndbl  (2): duration, duration_nintendo\ndttm (3): session_start, session_end, time_of_pull\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nsteam <- read_csv(\"data/raw/telemetry_steam_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 550724 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): pid, title_id, platform, game_ref\ndbl  (4): hour, steam_id, playtime_forever, playtime_2weeks\nlgl  (1): genre\ndttm (1): timestamp\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nxbox <- read_csv(\"data/raw/telemetry_xbox_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 4582917 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (11): pid, title_id, title_placement, publisher_id, gameplay_type, genr...\ndbl   (1): duration\ndttm  (3): session_start, session_end, time_of_pull\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\ndat_cog <- read_csv(\"data/raw/cognitive_tasks_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 247756 Columns: 38\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (7): pid, task, device_type, stim, location, resp1, resp2\ndbl  (21): wave, rt, trial_index, time_elapsed, block_trial_count, practice,...\nlgl   (9): response, timeout, success, failed_images, failed_audio, failed_v...\ndttm  (1): datetime\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# non- and idle games lists are in helpers.R\n\n# Arrange data to calculate differences correctly\nsteam_clean <- steam |>\n  filter(!title_id %in% idle_games & !title_id %in% non_games) |>\n  mutate(\n    steam_id = as.character(steam_id),\n    pid = as.character(pid)\n  ) |>\n  arrange(pid, title_id, timestamp) |>\n  group_by(pid, steam_id) |>\n  mutate(\n    # Calculate time difference between consecutive polls for the same user/game\n    time_diff_hours = as.numeric(difftime(\n      timestamp,\n      lag(timestamp),\n      units = \"hours\"\n    )),\n    # Calculate playtime difference\n    playtime_diff = playtime_forever - lag(playtime_forever)\n  ) |>\n  ungroup() |>\n  # Filter out invalid calculations:\n  # - First entry for each user/game (lag is NA)\n  # - Negative playtime difference (data anomaly or reset?)\n  # - Large time gaps between polls (e.g., > 2 hours for hourly polling, indicates missed polls or stopped tracking)\n  filter(\n    !is.na(playtime_diff),\n    playtime_diff >= 0,\n    !is.na(time_diff_hours),\n    time_diff_hours > 0,\n    time_diff_hours < 2 # Assuming roughly hourly polls\n  ) |>\n  # If playtime_diff is large, it might span multiple hours.\n  # This calculation assumes playtime is evenly distributed over the polling interval.\n  # A more complex approach might be needed for precise hourly allocation if intervals vary widely.\n  # For simplicity here, we assign the entire playtime_diff to the hour the poll *ended*.\n  mutate(\n    minutes = playtime_diff,\n    date = as.Date(timestamp),\n    hour = hour(timestamp),\n    datetime_hour_start = ymd_hms(\n      paste0(date, \" \", sprintf(\"%02d\", hour), \":00:00\"),\n      tz = \"UTC\"\n    )\n  ) |>\n  # filter out rows where 3+ games are being played simultaneously\n  group_by(pid, datetime_hour_start) |>\n  mutate(concurrent_titles = n_distinct(steam_id[minutes > 0])) |>\n  ungroup() |>\n  mutate(minutes = ifelse(concurrent_titles >= 3, 0, minutes)) |>\n  group_by(pid, steam_id) |>\n  # Calculate difference from previous hour and identify new sessions\n  mutate(\n    hour_diff = as.numeric(difftime(\n      datetime_hour_start,\n      lag(datetime_hour_start),\n      units = \"hours\"\n    )),\n    is_new_session = ifelse(is.na(hour_diff) | hour_diff > 1, 1, 0),\n    session_group_id = cumsum(is_new_session),\n    session_start = datetime_hour_start,\n    session_end = datetime_hour_start + hours(1) # Session ends at the end of the last hour block played\n  ) |>\n  filter(minutes > 0 & minutes < 120) |>\n  ungroup()\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Clean Xbox data and keep only active gaming sessions\n# In particular, canonicalize overlapping Xbox sessions per pid:\n# - at most one title at any instant\n# - handoff tolerance 'tol_sec' (short overlaps => later-starting title wins)\n# - ≥3 concurrent titles => drop that slice\n\nxbox_clean <- xbox |>\n  filter(title_placement == \"Full\") |>\n  filter(genres != \"Video\") |>\n  filter(\n    !is.na(session_start),\n    !is.na(session_end),\n    session_end > session_start\n  ) |>\n  filter(title_id != \"e1924c10-9c91-4652-81b9-8ca0670e77a7\") |> # something weird with this title, almost every player has played it and it accounts for 4x the playtime of the next-highest game - and it's unrated. I suspect it's the home screen or something.\n  filter(duration <= 600) |>\n  arrange(pid, session_start, session_end) |>\n  canonicalize_xbox_sessions(tol_sec = 60)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntol <- dseconds(60)\n\nnintendo_clean <- lazy_dt(nintendo, immutable = TRUE) |>\n  filter(\n    !is.na(session_start),\n    !is.na(session_end),\n    session_end > session_start,\n    session_start < time_of_pull\n  ) |>\n  arrange(pid, title_id, session_start, session_end) |>\n  group_by(pid, title_id) |> \n  mutate(\n    start_num = as.numeric(session_start),\n    end_num = as.numeric(session_end),\n    prev_max_end = lag(cummax(end_num), default = -Inf),\n    new_cluster = start_num > (prev_max_end + as.numeric(tol)),\n    cluster = cumsum(new_cluster),\n    dur_sec = end_num - start_num\n  ) |> \n  group_by(pid, title_id, cluster) |>\n  slice_max(n = 1, order_by = dur_sec, with_ties = FALSE) |>\n  ungroup() |> \n  mutate(duration = dur_sec / 60) |> \n  select(pid, title_id, session_start, session_end, duration) |>\n  filter(duration <= 600) |>\n  as_tibble()\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Only include non-pilot-study participants who qualified at intake\ndat_cog <- dat_cog |>\n  filter(\n    pid %in%\n      unique(intake$pid[intake$qualified & intake$cohort != \"Platform Pilot\"])\n  )\n\n# Take relevant variables and observations only\n# `score_final` is automatically added to all rows so distinct works here\ndat_cog <- dat_cog |>\n  filter(practice == 0, task == \"simon\") |>\n  add_count(pid, wave, name = \"n_trials\") |>\n  distinct(\n    pid,\n    wave,\n    datetime,\n    device_type,\n    n_trials,\n    score_final,\n    meanrt_final\n  )\n\ndat_cog <- dat_cog |>\n  mutate(wave = factor(wave)) |>\n  arrange(wave, pid)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# import ethnicity data using the census API and tidycensus\nethnicity_vars <- load_variables(2020, \"pl\", cache = TRUE) |>\n  filter(name %in% paste0(\"P1_00\", 3:9, \"N\"))\n\nethnicity_us <- get_decennial(\n  geography = \"us\",\n  variables = ethnicity_vars$name,\n  year = 2020,\n) |>\n  left_join(ethnicity_vars, by = c(\"variable\" = \"name\")) |> \n  mutate(\n    label = map_chr(label, ~ str_trim(tail(str_split(.x, \"!!\")[[1]], 1)))\n  ) |>\n  select(label, gen_pop = value) |>\n  mutate(\n    label = case_match(\n      label,\n      c(\"White alone\") ~ \"White\",\n      c(\"Black or African American alone\", \"Black or African American\") ~\n        \"Black\",\n      c(\"Asian alone\") ~ \"Asian\",\n      c(\"American Indian and Alaska Native alone\") ~\n        \"American Indian and Alaska Native\",\n      c(\"Native Hawaiian and Other Pacific Islander alone\") ~\n        \"Native Hawaiian and Other Pacific Islander\",\n      c(\"Some Other Race alone\") ~ \"Other\",\n      c(\"Population of two or more races:\") ~ \"Two or More Races\",\n      .default = \"Other\"\n    )\n  ) |>\n  mutate(\n    gen_prop = gen_pop / sum(gen_pop, na.rm = TRUE),\n    moe = 1.96 * sqrt(gen_pop * (1 - gen_pop / sum(gen_pop))) / sum(gen_pop),\n    country = \"US\"\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nGetting data from the 2020 decennial Census\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: • You have not set a Census API key. Users without a key are limited to 500\nqueries per day and may experience performance limitations.\nℹ For best results, get a Census API key at\nhttp://api.census.gov/data/key_signup.html and then supply the key to the\n`census_api_key()` function to use it throughout your tidycensus session.\nThis warning is displayed once per session.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nUsing the PL 94-171 Redistricting Data Summary File\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNote: 2020 decennial Census data use differential privacy, a technique that\nintroduces errors into data to preserve respondent confidentiality.\nℹ Small counts should be interpreted with caution.\nℹ See https://www.census.gov/library/fact-sheets/2021/protecting-the-confidentiality-of-the-2020-census-redistricting-data.html for additional guidance.\nThis message is displayed once per session.\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nage_uk <- read_csv(\n  \"data/census/TS009-2021-2-filtered-2025-03-05T23-18-32Z.csv\"\n) |>\n  pivot_wider(\n    id_cols = c(`Age (91 categories) Code`, `Age (91 categories)`),\n    names_from = `Sex (2 categories)`,\n    values_from = Observation\n  ) |> \n  mutate(total = Female + Male) |> \n  select(age = `Age (91 categories)`, female = Female, male = Male, total)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 182 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): England and Wales Code, England and Wales, Sex (2 categories), Age ...\ndbl (3): Sex (2 categories) Code, Age (91 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\n# https://www.ons.gov.uk/datasets/TS021/editions/2021/versions/1/filter-outputs/f1addb18-dcb8-4adb-98a8-abeb9108c330#get-data\nethnicity_uk <- read_csv(\n  \"data/census/TS021-2021-1-filtered-2025-03-05T23-25-05Z.csv\"\n) |>\n  # Optionally drop the row for \"Does not apply\"\n  filter(`Ethnic group (20 categories)` != \"Does not apply\") |> \n  mutate(\n    label = case_when(\n      str_detect(`Ethnic group (20 categories)`, \"^Asian\") ~ \"Asian\",\n      str_detect(`Ethnic group (20 categories)`, \"^Black\") ~ \"Black\",\n      str_detect(`Ethnic group (20 categories)`, \"^Mixed\") ~\n        \"Two or More Races\",\n      str_detect(`Ethnic group (20 categories)`, \"^White\") ~ \"White\",\n      str_detect(`Ethnic group (20 categories)`, \"^Other ethnic group\") ~\n        \"Other\",\n      TRUE ~ \"Other\" # fallback if nothing matches\n    )\n  ) |>\n  group_by(label) |>\n  summarize(gen_pop = sum(Observation, na.rm = TRUE)) |>\n  ungroup() |>\n  mutate(\n    gen_prop = gen_pop / sum(gen_pop),\n    moe = 1.96 * sqrt(gen_pop * (1 - gen_pop / sum(gen_pop))) / sum(gen_pop),\n    country = \"UK\"\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 20 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): England and Wales Code, England and Wales, Ethnic group (20 categor...\ndbl (2): Ethnic group (20 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\neducation_uk <- read_csv(\n  \"data/census/TS067-2021-3-filtered-2025-03-05T23-37-22Z.csv\"\n) |>\n  select(4:5) |>\n  rename_with(~ c(\"level\", \"gen_pop\")) |>\n  filter(level != \"Does not apply\") |>\n  mutate(\n    level = case_when(\n      str_detect(level, \"No qualifications\") ~ \"No formal qualifications\",\n      str_detect(level, \"Level 1\") ~\n        \"One to four GCSE passes (grade A* to C or grade 4 and above) and any other GCSEs at other grades, or equivalent qualifications\",\n      str_detect(level, \"Level 2\") ~\n        \"Five or more GCSE passes (grade A* to C or grade 4 and above) or equivalent qualifications\",\n      str_detect(level, \"Level 3\") ~\n        \"Two or more A Levels or equivalent qualifications\",\n      str_detect(level, \"Level 4\") ~\n        \"Higher National Certificate, Higher National Diploma, Bachelor's degree, or post-graduate qualifications\",\n      str_detect(level, \"Other:\") ~ \"Other qualifications\",\n      str_detect(level, \"Apprenticeship\") ~ \"Apprenticeships\",\n      TRUE ~ \"Other qualifications\"\n    ),\n    level = factor(level, levels = unique(level)),\n    moe = 1.96 * sqrt(gen_pop * (1 - gen_pop / sum(gen_pop))) / sum(gen_pop),\n    gen_prop = gen_pop / sum(gen_pop),\n    country = \"UK\"\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 8 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): England and Wales Code, England and Wales, Highest level of qualifi...\ndbl (2): Highest level of qualification (8 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n## Write clean data files\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Construct path and directory\npath_out <- path(\"data\", \"clean\")\ndir_create(path_out)\n\n# Write files\nwrite_csv(intake, path(path_out, \"intake\", ext = \"csv.gz\"))\nwrite_csv(diary, path(path_out, \"diary\", ext = \"csv.gz\"))\nwrite_csv(panel, path(path_out, \"panel\", ext = \"csv.gz\"))\nwrite_csv(nintendo_clean, path(path_out, \"nintendo\", ext = \"csv.gz\"))\nwrite_csv(steam_clean, path(path_out, \"steam\", ext = \"csv.gz\"))\nwrite_csv(xbox_clean, path(path_out, \"xbox\", ext = \"csv.gz\"))\nwrite_csv(dat_cog, path(path_out, \"simon\", ext = \"csv.gz\"))\nwrite_csv(ethnicity_us, path(path_out, \"ethnicity_us\", ext = \"csv.gz\"))\nwrite_csv(ethnicity_uk, path(path_out, \"ethnicity_uk\", ext = \"csv.gz\"))\n```\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}