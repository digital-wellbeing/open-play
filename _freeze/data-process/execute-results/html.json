{
  "hash": "d835fde0025cdf501e2c4fb762799a2e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Clean raw data and save outputs\n---\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(data.table)\nlibrary(dtplyr)\nlibrary(fs)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.1     ✔ stringr   1.5.2\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::between()     masks data.table::between()\n✖ dplyr::filter()      masks stats::filter()\n✖ dplyr::first()       masks data.table::first()\n✖ lubridate::hour()    masks data.table::hour()\n✖ lubridate::isoweek() masks data.table::isoweek()\n✖ dplyr::lag()         masks stats::lag()\n✖ dplyr::last()        masks data.table::last()\n✖ lubridate::mday()    masks data.table::mday()\n✖ lubridate::minute()  masks data.table::minute()\n✖ lubridate::month()   masks data.table::month()\n✖ lubridate::quarter() masks data.table::quarter()\n✖ lubridate::second()  masks data.table::second()\n✖ purrr::transpose()   masks data.table::transpose()\n✖ lubridate::wday()    masks data.table::wday()\n✖ lubridate::week()    masks data.table::week()\n✖ lubridate::yday()    masks data.table::yday()\n✖ lubridate::year()    masks data.table::year()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\n# Load custom functions\nsource(\"R/helpers.R\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nintake <- read_csv(\"data/raw/survey_intake_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 34295 Columns: 98\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (59): pid, status, cohort, country, used_platforms, eligible_platforms,...\ndbl  (20): panels_completed, diaries_completed, total_recent_play_accounted_...\nlgl  (17): plays_xbox, plays_steam, plays_nintendo, plays_ios, plays_android...\ndttm  (2): enrollment_date, nintendo_account_creation_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\ndiary <- read_csv(\"data/raw/survey_diary_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 18829 Columns: 83\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (41): pid, bpnsfs_dup_item, played24hr, socialGaming_4, socialGaming_5,...\ndbl  (40): wave, survey_duration, bpnsfs_1, bpnsfs_2, bpnsfs_3, bpnsfs_4, bp...\nlgl   (1): bpnsfs_failed_att_check\ndttm  (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\npanel <- read_csv(\"data/raw/survey_panel_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 7038 Columns: 159\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (54): pid, cohort, bangs_dup_item, positives, problematicPlay, gdt_1, g...\ndbl  (76): wave, survey_duration, bangs_1, bangs_2, bangs_3, bangs_4, bangs_...\nlgl  (16): bangs_failed_att_check, BFI-2-XS_1, BFI-2-XS_2, BFI-2-XS_3, BFI-2...\ndttm  (1): date\ndate  (3): recentSessions_1_1, recentSessions_2_1, recentSessions_3_1\ntime  (9): mctq_3_1, mctq_3_3, mctq_3_5, mctq_6_1, mctq_6_3, mctq_6_5, recen...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nnintendo <- read_csv(\"data/raw/telemetry_nintendo_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 830853 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (6): pid, title_id, operation_mode, device_type, genre, game_ref\ndbl  (2): duration, duration_nintendo\ndttm (3): session_start, session_end, time_of_pull\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nsteam <- read_csv(\"data/raw/telemetry_steam_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 1046589 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): pid, title_id, platform, game_ref\ndbl  (4): hour, steam_id, playtime_forever, playtime_2weeks\nlgl  (1): genre\ndttm (1): timestamp\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nxbox <- read_csv(\"data/raw/telemetry_xbox_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 4582917 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (11): pid, title_id, title_placement, publisher_id, gameplay_type, genr...\ndbl   (1): duration\ndttm  (3): session_start, session_end, time_of_pull\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nios <- read_csv(\"data/raw/telemetry_ios_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 3633 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): pid\ndbl  (1): total_gaming_minutes\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nandroid <- read_csv(\"data/raw/telemetry_android_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 2576 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): pid\ndbl  (1): total_gaming_minutes\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\ndat_cog <- read_csv(\"data/raw/cognitive_tasks_raw.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 247756 Columns: 38\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (7): pid, task, device_type, stim, location, resp1, resp2\ndbl  (21): wave, rt, trial_index, time_elapsed, block_trial_count, practice,...\nlgl   (9): response, timeout, success, failed_images, failed_audio, failed_v...\ndttm  (1): datetime\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# non- and idle games lists are in helpers.R\n\n# Arrange data to calculate differences correctly\nsteam_clean <- steam |>\n  filter(!title_id %in% idle_games & !title_id %in% non_games) |>\n  mutate(\n    steam_id = as.character(steam_id),\n    pid = as.character(pid)\n  ) |>\n  arrange(pid, title_id, timestamp) |>\n  group_by(pid, steam_id) |>\n  mutate(\n    # Calculate time difference between consecutive polls for the same user/game\n    time_diff_hours = as.numeric(difftime(\n      timestamp,\n      lag(timestamp),\n      units = \"hours\"\n    )),\n    # Calculate playtime difference\n    playtime_diff = playtime_forever - lag(playtime_forever)\n  ) |>\n  ungroup() |>\n  # Filter out invalid calculations:\n  # - First entry for each user/game (lag is NA)\n  # - Negative playtime difference (data anomaly or reset?)\n  # - Large time gaps between polls (e.g., > 2 hours for hourly polling, indicates missed polls or stopped tracking)\n  filter(\n    !is.na(playtime_diff),\n    playtime_diff >= 0,\n    !is.na(time_diff_hours),\n    time_diff_hours > 0,\n    time_diff_hours < 2 # Assuming roughly hourly polls\n  ) |>\n  # If playtime_diff is large, it might span multiple hours.\n  # This calculation assumes playtime is evenly distributed over the polling interval.\n  # A more complex approach might be needed for precise hourly allocation if intervals vary widely.\n  # For simplicity here, we assign the entire playtime_diff to the hour the poll *ended*.\n  mutate(\n    minutes = playtime_diff,\n    date = as.Date(timestamp),\n    hour = hour(timestamp),\n    datetime_hour_start = ymd_hms(\n      paste0(date, \" \", sprintf(\"%02d\", hour), \":00:00\"),\n      tz = \"UTC\"\n    )\n  ) |>\n  # filter out rows where 3+ games are being played simultaneously\n  group_by(pid, datetime_hour_start) |>\n  mutate(concurrent_titles = n_distinct(steam_id[minutes > 0])) |>\n  ungroup() |>\n  mutate(minutes = ifelse(concurrent_titles >= 3, 0, minutes)) |>\n  group_by(pid, steam_id) |>\n  # Calculate difference from previous hour and identify new sessions\n  mutate(\n    hour_diff = as.numeric(difftime(\n      datetime_hour_start,\n      lag(datetime_hour_start),\n      units = \"hours\"\n    )),\n    is_new_session = ifelse(is.na(hour_diff) | hour_diff > 1, 1, 0),\n    session_group_id = cumsum(is_new_session),\n    session_start = datetime_hour_start,\n    session_end = datetime_hour_start + hours(1) # Session ends at the end of the last hour block played\n  ) |>\n  filter(minutes > 0 & minutes < 120) |>\n  ungroup()\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Clean Xbox data and keep only active gaming sessions\n# In particular, canonicalize overlapping Xbox sessions per pid:\n# - at most one title at any instant\n# - handoff tolerance 'tol_sec' (short overlaps => later-starting title wins)\n# - ≥3 concurrent titles => drop that slice\n\nxbox_clean <- xbox |>\n  filter(title_placement == \"Full\") |>\n  filter(genres != \"Video\") |>\n  filter(\n    !is.na(session_start),\n    !is.na(session_end),\n    session_end > session_start\n  ) |>\n  filter(title_id != \"e1924c10-9c91-4652-81b9-8ca0670e77a7\") |> # something weird with this title, almost every player has played it and it accounts for 4x the playtime of the next-highest game - and it's unrated. I suspect it's the home screen or something.\n  filter(duration <= 600) |>\n  arrange(pid, session_start, session_end) |>\n  canonicalize_xbox_sessions(tol_sec = 60)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntol <- dseconds(60)\n\nnintendo_clean <- lazy_dt(nintendo, immutable = TRUE) |>\n  filter(\n    !is.na(session_start),\n    !is.na(session_end),\n    session_end > session_start,\n    session_start < time_of_pull\n  ) |>\n  arrange(pid, title_id, session_start, session_end) |>\n  group_by(pid, title_id) |> \n  mutate(\n    start_num = as.numeric(session_start),\n    end_num = as.numeric(session_end),\n    prev_max_end = lag(cummax(end_num), default = -Inf),\n    new_cluster = start_num > (prev_max_end + as.numeric(tol)),\n    cluster = cumsum(new_cluster),\n    dur_sec = end_num - start_num\n  ) |> \n  group_by(pid, title_id, cluster) |>\n  slice_max(n = 1, order_by = dur_sec, with_ties = FALSE) |>\n  ungroup() |> \n  mutate(duration = dur_sec / 60) |> \n  select(pid, title_id, session_start, session_end, duration, device_type, operation_mode) |>\n  filter(duration <= 600) |>\n  as_tibble()\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Only include non-pilot-study participants who qualified at intake\ndat_cog <- dat_cog |>\n  filter(\n    pid %in%\n      unique(intake$pid[intake$qualified & intake$cohort != \"Platform Pilot\"])\n  )\n\n# Take relevant variables and observations only\n# `score_final` is automatically added to all rows so distinct works here\ndat_cog <- dat_cog |>\n  filter(practice == 0, task == \"simon\") |>\n  add_count(pid, wave, name = \"n_trials\") |>\n  distinct(\n    pid,\n    wave,\n    datetime,\n    device_type,\n    n_trials,\n    score_final,\n    meanrt_final\n  )\n\ndat_cog <- dat_cog |>\n  mutate(wave = factor(wave)) |>\n  arrange(wave, pid)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nandroid <- android |> \n  mutate(platform = \"Android\") |> \n  select(pid, platform, day_local = date, minutes = total_gaming_minutes)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nios <- ios |> \n  mutate(platform = \"iOS\") |> \n  select(pid, platform, day_local = date, minutes = total_gaming_minutes)\n```\n:::\n\n\n## Write clean data files\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Construct path and directory\npath_out <- path(\"data\", \"clean\")\ndir_create(path_out)\n\n# Write files\nwrite_csv(intake, path(path_out, \"intake\", ext = \"csv.gz\"))\nwrite_csv(diary, path(path_out, \"diary\", ext = \"csv.gz\"))\nwrite_csv(panel, path(path_out, \"panel\", ext = \"csv.gz\"))\nwrite_csv(nintendo_clean, path(path_out, \"nintendo\", ext = \"csv.gz\"))\nwrite_csv(steam_clean, path(path_out, \"steam\", ext = \"csv.gz\"))\nwrite_csv(xbox_clean, path(path_out, \"xbox\", ext = \"csv.gz\"))\nwrite_csv(ios, path(path_out, \"ios\", ext = \"csv.gz\"))\nwrite_csv(android, path(path_out, \"android\", ext = \"csv.gz\"))\nwrite_csv(dat_cog, path(path_out, \"simon\", ext = \"csv.gz\"))\n```\n:::\n\n",
    "supporting": [
      "data-process_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}