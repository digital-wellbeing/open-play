---
title: "A multi-platform dataset of digital trace data from video games"
author:
  - name: Nick Ballou
    corresponding: false
    orcid: 0000-0003-4126-0696
    email: nick@nickballou.com
    affiliations:
      - name: University of Oxford
        department: Oxford Internet Institute
    # roles:
    #   - conceptualization
    #   - data curation
    #   - methodology
    #   - formal analysis
    #   - writing
    
  - name: Tamás Andrei Földes
    corresponding: false
    orcid: 0000-0002-0623-9149
    email: tamas.foldes@oii.ox.ac.uk
    affiliations:
      - name: University of Oxford
        department: Oxford Internet Institute
    # roles:
    #   - conceptualization
    #   - data curation
    #   - methodology
    #   - formal analysis
    #   - writing
      
  - name: Matti Vuorre
    corresponding: false
    orcid: 0000-0001-5052-066X
    affiliations:
      - name: Tilburg University
      - name: University of Oxford
        department: Oxford Internet Institute
    # roles:
    #   - methodology
    #   - funding acquisition
    #   - formal analysis
    #   - editing
      
  - name: Thomas Hakman
    corresponding: false
    orcid: 0009-0009-8292-2482
    email: nick@nickballou.com
    affiliations:
      - name: University of Oxford
        department: Oxford Internet Institute
    # roles:
    #   - data curation
    #   - validation
    #   - editing
      
  - name: Kristoffer Magnusson
    corresponding: false
    orcid: 0000-0003-0713-0556
    affiliations:
      - name: Karolinska Institute
      - name: University of Oxford
        department: Oxford Internet Institute
    # roles:
    #   - methodology
    #   - editing
      
  - name: Andrew K Przybylski
    corresponding: true
    email: andy.pryzbylski@oii.ox.ac.uk
    orcid: 0000-0003-4126-0696
    affiliations:
      - name: University of Oxford
        department: Oxford Internet Institute
    # roles:
    #   - conceptualization
    #   - funding acquisition
    #   - project administration
    #   - editing
output: html_document
execute-dir: project
format: 
  html:
    toc: true
    toc-depth: 2
    code-fold: true
    code-summary: "Show/Hide Code"
    self-contained: false
    theme: cosmo
    highlight: tango

editor_options:
  chunk_output_type: console
  markdown:
    wrap: 72
warning: false
echo: false
---

```{r}
#| label: libraries

if (!require("pacman")) install.packages("pacman")
if (!require("devtools")) install.packages("devtools")
library(pacman)

if (!require("ggsankey")) devtools::install_github("davidsjoberg/ggsankey")

p_load(
  tidyverse, jsonlite, qualtRics, sjlabelled, hms, openxlsx, scales, qualtRics, here, scales, ggsankey, tidycensus, here, ggrepel
)

here::i_am("manuscripts/data-ms/data-ms.qmd")

theme_set(theme_minimal())
theme_update(
  strip.background = element_rect(fill = "black"),
  strip.text = element_text(color = "white", size = 10),
  panel.grid.minor = element_blank(),
  panel.border = element_rect(colour = "black", fill = NA, linewidth = 1),
)

set.seed(8675309)

options(scipen = 999)

```

```{r}
#| label: load-data

intake <- read_csv(here("data-minimal-pseudo/survey_intake.csv.gz"))
diary <- read_csv(here("data-minimal-pseudo/survey_diary.csv.gz"))
panel <- read_csv(here("data-minimal-pseudo/survey_panel.csv.gz"))

nintendo <- read_csv(here("data-minimal-pseudo/telemetry_nintendo.csv.gz"))
steam <- read_csv(here("data-minimal-pseudo/telemetry_steam.csv.gz"))
xbox <- read_csv(here("data-minimal-pseudo/telemetry_xbox.csv.gz"))

```

```{r}
#| label: custom-funcs

print_num <- function(num, accuracy = .1) {
  scales::number(num, 
                 accuracy = accuracy, 
                 scale_cut = scales::cut_long_scale())
}

```

```{r}
#| label: preprocess-steam

# TODO: filter by non-account sharing

# Arrange data to calculate differences correctly
steam_sum <- steam |>
  mutate(
    steam_id = as.character(steam_id),
    pid = as.character(pid)
  ) |>
  arrange(pid, title_id, timestamp) |>
  group_by(pid, steam_id) |>
  mutate(
    # Calculate time difference between consecutive polls for the same user/game
    time_diff_hours = as.numeric(difftime(timestamp, lag(timestamp), units = "hours")),
    # Calculate playtime difference
    playtime_diff = playtime_forever - lag(playtime_forever)
  ) |>
  ungroup() |>
  # Filter out invalid calculations:
  # - First entry for each user/game (lag is NA)
  # - Negative playtime difference (data anomaly or reset?)
  # - Large time gaps between polls (e.g., > 2 hours for hourly polling, indicates missed polls or stopped tracking)
  #   Adjust the threshold (e.g., 1.1 or 1.5 hours) as needed based on polling frequency and tolerance.
  filter(
    !is.na(playtime_diff),
    playtime_diff >= 0,
    !is.na(time_diff_hours),
    time_diff_hours > 0, time_diff_hours < 2 # Assuming roughly hourly polls
  ) |>
  # If playtime_diff is large, it might span multiple hours.
  # This calculation assumes playtime is evenly distributed over the polling interval.
  # A more complex approach might be needed for precise hourly allocation if intervals vary widely.
  # For simplicity here, we assign the entire playtime_diff to the hour the poll *ended*.
  mutate(
    minutes = playtime_diff,
    date = as.Date(timestamp),
    hour = hour(timestamp),
    datetime_hour_start = ymd_hms(paste0(date, " ", sprintf("%02d", hour), ":00:00"), tz = "UTC")
  ) |>
  group_by(pid, steam_id) |>
  # Calculate difference from previous hour and identify new sessions
  mutate(
    hour_diff = as.numeric(difftime(datetime_hour_start, lag(datetime_hour_start), units = "hours")),
    is_new_session = ifelse(is.na(hour_diff) | hour_diff > 1, 1, 0),
    session_group_id = cumsum(is_new_session),
    session_start = min(datetime_hour_start),
    session_end = max(datetime_hour_start) + hours(1) # Session ends at the end of the last hour block played
  ) |>
  filter(minutes > 0)
```

```{r}
#| label: preprocess-xbox

xbox_clean <- xbox |> 
  filter(title_placement == "Full") |> 
  filter(genres != "Video")
  
```

```{r}
#| label: preprocess-nintendo

nintendo_clean <- nintendo |> 
  filter(session_end <= time_of_pull)
  
```

```{r}
#| label: summary-stats

n_participants <- print_num(length(unique(panel$pid)))
n_daily <- print_num(nrow(diary))
n_biweekly <- print_num(nrow(panel))
n_sessions <- print_num(nrow(nintendo) + nrow(xbox) + nrow(steam_sum))
n_hours <- print_num((sum(nintendo$duration, na.rm = TRUE) + sum(xbox$duration, na.rm = TRUE) + sum(steam_sum$minutes, na.rm = TRUE))/60)

n_platforms <- table(stringr::str_count(intake$linked_platforms[!is.na(intake$linked_platforms)], ",") + 1)

```

```{r}
#| label: load-US-census-data

# import ethnicity data using the census API and tidycensus
ethnicity_vars <- load_variables(2020, "pl", cache = TRUE) |> 
  filter(name %in% paste0("P1_00", 3:9, "N"))

ethnicity_us <- get_decennial(
  geography = "us",
  variables = ethnicity_vars$name,
  year = 2020,
) |> 
  left_join(ethnicity_vars, by = c("variable" = "name")) %>%
  mutate(label = map_chr(label, ~ str_trim(tail(str_split(.x, "!!")[[1]], 1)))) |> 
  select(label, gen_pop = value) |> 
  mutate(
    label = case_match(label,
      c("White alone") ~ "White",
      c("Black or African American alone","Black or African American") ~ "Black",
      c("Asian alone") ~ "Asian",
      c("American Indian and Alaska Native alone") ~ "American Indian and Alaska Native",
      c("Native Hawaiian and Other Pacific Islander alone") ~ "Native Hawaiian and Other Pacific Islander",
      c("Some Other Race alone") ~ "Other",
      c("Population of two or more races:") ~ "Two or More Races",
      .default = "Other"
    )
  ) |> 
  mutate(
    gen_prop = gen_pop / sum(gen_pop, na.rm = TRUE),
    moe = 1.96 * sqrt(gen_pop * (1 - gen_pop / sum(gen_pop))) / sum(gen_pop),
    country = "US"
  )

```

```{r}
#| label: load-UK-census-data

age_uk <- read_csv(here("data-census/TS009-2021-2-filtered-2025-03-05T23-18-32Z.csv")) |> 
  pivot_wider(
    id_cols = c(`Age (91 categories) Code`, `Age (91 categories)`),
    names_from = `Sex (2 categories)`,
    values_from = Observation
  ) %>%
  mutate(total = Female + Male) %>%
  select(age = `Age (91 categories)`, female = Female, male = Male, total)

# https://www.ons.gov.uk/datasets/TS021/editions/2021/versions/1/filter-outputs/f1addb18-dcb8-4adb-98a8-abeb9108c330#get-data
ethnicity_uk <- read_csv(here("data-census/TS021-2021-1-filtered-2025-03-05T23-25-05Z.csv")) |> 
  # Optionally drop the row for "Does not apply"
  filter(`Ethnic group (20 categories)` != "Does not apply") %>%
  mutate(
    label = case_when(
      str_detect(`Ethnic group (20 categories)`, "^Asian") ~ "Asian",
      str_detect(`Ethnic group (20 categories)`, "^Black") ~ "Black",
      str_detect(`Ethnic group (20 categories)`, "^Mixed") ~ "Two or More Races",
      str_detect(`Ethnic group (20 categories)`, "^White") ~ "White",
      str_detect(`Ethnic group (20 categories)`, "^Other ethnic group") ~ "Other",
      TRUE ~ "Other"  # fallback if nothing matches
    )
  ) |> 
  group_by(label) |> 
  summarize(gen_pop = sum(Observation, na.rm = TRUE)) |> 
  ungroup() |> 
  mutate(
    gen_prop = gen_pop / sum(gen_pop),
    moe = 1.96 * sqrt(gen_pop * (1 - gen_pop / sum(gen_pop))) / sum(gen_pop),
    country = "UK"
  )

education_uk <- read_csv(here("data-census/TS067-2021-3-filtered-2025-03-05T23-37-22Z.csv")) |> 
  select(4:5) |> 
  rename_with(~ c("level","gen_pop")) |> 
  filter(level != "Does not apply") |> 
  mutate(
    level = case_when(
      str_detect(level, "No qualifications") ~ "No formal qualifications",
      str_detect(level, "Level 1") ~ "One to four GCSE passes (grade A* to C or grade 4 and above) and any other GCSEs at other grades, or equivalent qualifications",
      str_detect(level, "Level 2") ~ "Five or more GCSE passes (grade A* to C or grade 4 and above) or equivalent qualifications",
      str_detect(level, "Level 3") ~ "Two or more A Levels or equivalent qualifications",
      str_detect(level, "Level 4") ~ "Higher National Certificate, Higher National Diploma, Bachelor's degree, or post-graduate qualifications",
      str_detect(level, "Other:") ~ "Other qualifications",
      str_detect(level, "Apprenticeship") ~ "Apprenticeships",
      TRUE ~ "Other qualifications"
    ),
    level = factor(level, levels = unique(level)),
    moe = 1.96 * sqrt(gen_pop * (1 - gen_pop / sum(gen_pop))) / sum(gen_pop),
    gen_prop = gen_pop / sum(gen_pop),
    country = "UK"
  )

```

# Introduction

Scientists widely agree that digital trace data---behavioral logs
automatically collected by online platforms---are necessary to
understand the effects of technology on varied outcomes such as health,
wellbeing, academic achievement, and cognition. Users struggle to
accurately self-report even high-level measures of use (e.g., total
screentime) [@ParryEtAl2021systematic], and these high-level metrics are
generally poorly predictive of outcomes [@Orben2019Teens]. To
systematically understand the effects of technology, we therefore need
data that captures nuanced factors we now know to be much more
impactful: the frequency, duration, and time of day of each session, the
specific content engaged, and the trajectory of user behavior over time.
Digital trace data is well-suited to address this need.

As one of the world's foremost leisure activities, video games are a key
Digital trace data has been widely implemented in many studies of social
media and wellbeing, but in studies of video games has been much more
limited. In part, this is a function of availability: video game
consoles are restrictive and typically do not allow third party tracking
software; most video game platforms do not have a 1-click "download my
data" option offered by several social media platforms (e.g., TikTok,
Instagram); and there are thousands of individual games whose data may
be relevant for a given study or population.

Where trace data has been used in video games studies, it has largely
been limited to a single game [@VuorreEtAl2022Time;
@JohannesEtAl2021Video; @LarrieuEtAl2023How; @PerryEtAl2018onlineonly]
or platform [@BallouEtAl2023Gaming; @BallouEtAl2025Perceived] per user.
Previous studies that secured video game telemetry was widely limited to
a single game or a single gaming platform. However, as the data we
present here shows, players commonly use a wide range of games and
platforms. Capturing just one game or one gaming platform among
potentially many that the person may be engaging with---and affected by.
For example, a player may

Digital trace data on its own is limited however; without additional
information from users about how their lives are going, we will struggle
to understand the causal network. In the field of game analytics, a
number of studies have digital trace data to explore social networks, We
therefore see particular value in longitudinal studies that combine
comprehensive digital trace data with repeated surveys, in both
experimental and observational contexts. Ideally, surveys should be
frequent enough to capture short-term effects (e.g., playing a game to
recover from a stressful workday) and longer-term development (e.g., a
pattern of increasing play over time displacing sleep).

# Overview

This paper addresses this need for longitudinal digital trace data
across multiple gaming platforms. Here, we present a dataset consisting
of `r n_participants` participants, `r n_daily` daily surveys,
`r n_biweekly` surveys, and a total of `r n_hours` of gameplay
distributed across `r n_sessions`.

Digital trace data was sourced for five distinct platforms—Xbox,
Nintendo, Steam, iOS, and Android—through distinct piplines detailed
below.

The dataset is openly available at \[LINK\] under a CC0 license for
unrestricted reuse.

highlight that data collection methods are preregistered 

# Design

```{r}
#| label: fig-sankey

lvl <- c(
  "Screened",
  "Ineligible",
  "No recent trace data",
  "Did not begin surveys",
  "Linked ≥1 account",
  "Recent trace data",
  "Began surveys"
)

node_counts <- intake |>
  transmute(
    stage1 = "Screened",
    stage2 = ifelse(is.na(linked_platforms), "Ineligible",    "Linked ≥1 account"),
    stage3 = ifelse(qualified, "Recent trace data", "No recent trace data"),
    stage4 = ifelse(pid %in% panel$pid,      "Began surveys", "Did not begin surveys")
  ) |>
  pivot_longer(everything(), names_to = "stage", values_to = "node") |>
  filter(!is.na(node)) |>
  count(node, name = "n")

sankey_data <- intake |>
  transmute(
    Screening = "Screened",
    Linking = ifelse(is.na(linked_platforms), "Ineligible",    "Linked ≥1 account"),
    `Account Validation` = ifelse(qualified, "Recent trace data", "No recent trace data"),
    Surveys = ifelse(pid %in% panel$pid,      "Began surveys", "Did not begin surveys")
  ) |>
  make_long(Screening, Linking, `Account Validation`, Surveys) |>
  left_join(node_counts, by = "node") |>
  mutate(
    node = factor(node, levels = rev(lvl)),
    next_node = factor(next_node, levels = rev(lvl)),
    # build a plotmath expression: bold("Label")~"\n"~Count
    node_label = sprintf('atop(bold("%s"), "%s")', node, n)
  )

# 2. plot with parse = TRUE
ggplot(sankey_data,
       aes(x = x,
           next_x = next_x,
           node = node,
           next_node = next_node,
           fill = factor(node),
           label = node_label)) +
  geom_sankey(flow.alpha = .6, node.color = "gray30") +
  # pass parse = TRUE into the label layer
  geom_sankey_label(parse = TRUE,
                    size = 3, 
                    color = "white", 
                    fill = "gray40") +
  scale_fill_viridis_d(drop = FALSE) +
  theme_sankey() +
  theme(
    legend.position = "none",
    axis.text.y     = element_blank(),
    axis.ticks.y    = element_blank(),
    axis.title.x    = element_blank()
  )
```

The study consisted of four stages (@fig-sankey).

## Stage 1: Screening

In the first stage, we screened participants in order to find people
aged 18-40 who (1) self-report playing video games, (2) self-report that
at least 50% of their total video game play takes place on the platforms
included in the study, and (3) were willing to link their gaming
accounts to provide digital trace data. We screened participants from
two panel sources: PureProfile and Prolific.

Participants were recruited under an initial set of ethnicity‐based
quotas designed to mirror the general population’s demographic
composition. After we reached approximately 50% of our target sample
under quota constraints and found that further quota‐eligible recruits
were scarce, we suspended the quotas for the remainder of data
collection; all subsequent participants were enrolled on a first‐come,
first‐served basis. Final sample characteristic reflect both
quota‐driven and open‐enrollment phases (see below).

## Stage 2: Account Linking

Participants who were deemed eligible during screening proceeded
directly to an account linking survey wherein they provided details of
the gaming platforms they actively use. For UK participants, this
includes Nintendo Switch, Steam, Android and iOS. For US participants,
this includes the same four alongside Xbox. Details of how participants
linked each type of account are shown in @tbl-platforms.

+--------------+--------------+--------------+--------------+
| Platform     | Data Source  | Account      | Type of Data |
|              |              | Linking      | Collected    |
|              |              | Process      |              |
+==============+==============+==============+==============+
| Nintendo     | Data-sharing | Participants | Session      |
|              | agreements   | share an     | records      |
|              | with         | identifier   | (what game   |
|              | Nintendo of  | contained    | was played,  |
|              | America (US) | within a QR  | at what      |
|              | and Nintendo | code on      | time, for    |
|              | of Europe    | Nintendo web | how long)    |
|              | (UK)         | interface\[\ | for 1st      |
|              |              | [1           | party games  |
|              |              | \]](#_ftn1). | (games       |
|              |              | Nintendo of  | published in |
|              |              | A            | whole or in  |
|              |              | m            | part by      |
|              |              | erica/Europe | Nintendo,    |
|              |              | uses this    | but not by   |
|              |              | identifier   | third party  |
|              |              | to retrieve  | publishers   |
|              |              | gameplay     | such as      |
|              |              | data and     | Electronic   |
|              |              | share it     | Arts). In    |
|              |              | with the     | previous     |
|              |              | research     | research,    |
|              |              | team.        | Nint e       |
|              |              |              | n            |
|              |              | \[\[1\       | do-published |
|              |              | \]\]         | games        |
|              |              | (#\_ftnref1) | accounted    |
|              |              | \<https://a  | for 65% of   |
|              |              | c            | Switch       |
|              |              | c            | playtime     |
|              |              | ounts.ninten | @BallouEtAl  |
|              |              | do           | 2            |
|              |              | .            | 0            |
|              |              | com/qrcode\> | 25Perceived. |
+--------------+--------------+--------------+--------------+
| Xbox (US     | Data-sharing | Participants | Session      |
| only)        | agreement    | consent to   | records      |
|              | with         | data sharing | (what game   |
|              | Microsoft    | by opting in | was played,  |
|              |              | to the study | at what      |
|              |              | on Xbox      | time, for    |
|              |              | Insiders\[\  | how long).   |
|              |              | [            | The name of  |
|              |              | 1\]](#_ftn1) | the game     |
|              |              | with their   | replaced     |
|              |              | Xbox         | with a       |
|              |              | account.     | random       |
|              |              | Microsoft    | persistent   |
|              |              | retrieved    | identifier   |
|              |              | gameplay     | for all      |
|              |              | data for all | third-party  |
|              |              | consented    | games (i.e., |
|              |              | accounts,    | those not    |
|              |              | and shares   | published by |
|              |              | it with the  | Xbox Game    |
|              |              | research     | Studios),    |
|              |              | team in      | but genre(s) |
|              |              | p            | and age      |
|              |              | seudonymized | ratings are  |
|              |              | form.        | shared.      |
|              |              |              |              |
|              |              | \[\[1\       |              |
|              |              | \]\]         |              |
|              |              | (#\_ftnref1) |              |
|              |              | \<https://s  |              |
|              |              | u            |              |
|              |              | p            |              |
|              |              | port.xbox.co |              |
|              |              | m            |              |
|              |              | /            |              |
|              |              | en-US/help/a |              |
|              |              | c            |              |
|              |              | c            |              |
|              |              | ount-profile |              |
|              |              | /            |              |
|              |              | m            |              |
|              |              | anage-accoun |              |
|              |              | t            |              |
|              |              | /            |              |
|              |              | guide-to-ins |              |
|              |              | i            |              |
|              |              | d            |              |
|              |              | er-program\> |              |
+--------------+--------------+--------------+--------------+
| Steam        | Custom web   | Participants | Incremental  |
|              | app (Gam e   | sign up for  | playtime per |
|              | p            | Ga m         | game (every  |
|              | lay.Science) | e            | hour, the    |
|              |              | play.Science | total time   |
|              |              | ( \<         | spent        |
|              |              | h            | playing      |
|              |              | ttps://gamep | during the   |
|              |              | la           | previous     |
|              |              | y            | hour)        |
|              |              | .science),\> |              |
|              |              | an           |              |
|              |              | open-source  |              |
|              |              | platform for |              |
|              |              | tracking     |              |
|              |              | Steam        |              |
|              |              | gameplay.    |              |
|              |              | Participants |              |
|              |              | consent to   |              |
|              |              | have their   |              |
|              |              | gameplay     |              |
|              |              | data         |              |
|              |              | monitored    |              |
|              |              | for the      |              |
|              |              | duration of  |              |
|              |              | the study.   |              |
|              |              | Their Steam  |              |
|              |              | ID is        |              |
|              |              | a            |              |
|              |              | uthenticated |              |
|              |              | using the    |              |
|              |              | official     |              |
|              |              | Steam a      |              |
|              |              | u            |              |
|              |              | thentication |              |
|              |              | API          |              |
|              |              | (OpenID).    |              |
+--------------+--------------+--------------+--------------+
| iOS          | iOS Screen   | At each      | Total weekly |
|              | Time         | biweekly     | playtime per |
|              | Screenshots  | survey,      | game (e.g.,  |
|              |              | participants | 2 hours on   |
|              |              | submit       | game X, 5    |
|              |              | screenshots  | hours on     |
|              |              | from the     | game Y)      |
|              |              | built-in iOS |              |
|              |              | Screen Time  |              |
|              |              | app. These   |              |
|              |              | show details |              |
|              |              | of the       |              |
|              |              | previous 3   |              |
|              |              | weeks’ of    |              |
|              |              | gaming app   |              |
|              |              | use (whats   |              |
|              |              | games were   |              |
|              |              | played and   |              |
|              |              | for how      |              |
|              |              | long). Data  |              |
|              |              | was          |              |
|              |              | extracted    |              |
|              |              | using OCR.   |              |
+--------------+--------------+--------------+--------------+
| Android      | Digital      | At each      | Total weekly |
|              | Wellbeing    | biweekly     | playtime per |
|              | Screenshots  | survey,      | game (e.g.,  |
|              |              | participants | 2 hours on   |
|              |              | submitted    | game X, 5    |
|              |              | screenshots  | hours on     |
|              |              | from the     | game Y)      |
|              |              | Digital      |              |
|              |              | Screen Time  |              |
|              |              | app, if      |              |
|              |              | available on |              |
|              |              | their        |              |
|              |              | Android OS.  |              |
|              |              | These show   |              |
|              |              | details of   |              |
|              |              | the previous |              |
|              |              | 3 weeks’ of  |              |
|              |              | phone use    |              |
|              |              | (what app    |              |
|              |              | categories   |              |
|              |              | are used and |              |
|              |              | for how      |              |
|              |              | long). Data  |              |
|              |              | was          |              |
|              |              | extracted    |              |
|              |              | using OCR.   |              |
+--------------+--------------+--------------+--------------+

: : Platform Details {#tbl-platforms}

## Stage 3: Account Validation

After players completed the account linking process, we . Participants
needed to have valid telemetry from at least one platform in order to be
eligible for the next stage of the study. Participants who did not have
valid telemetry were excluded from the study

## Stage 4: Surveys

Eligible participants were invited to complete 6 waves of biweekly surveys,
one every two weeks. Eligible US participants will additionally be
invited to complete daily diary surveys for 30 days, concurrently with
the first biweekly surveys. Running survey types concurrently allows us to
harmonize distribution across regions without delaying the UK sample on
the US sample’s account, and to minimize attrition.

Diary survey links were sent every day at 2pm local time for the
participant and remained available until 3am. Biweekly survey links were
sent every second week from the first day of the study at 12pm and
remained available for 96 hours.

# Participants

```{r}
#| label: participant-gender

gender_counts <- intake |> 
  filter(country != "OTHER") |> 
  mutate(
    gender = ifelse(gender %in% c("Man", "Woman"), gender, "Other")
  ) |> 
  group_by(qualified) |>
  count(gender) |> 
  mutate(
    prop = paste0(100*round(prop.table(n), 3), "%")
  )

gender_text_all <- with(gender_counts,
                    paste0(gender, " (", n, ", ", prop, ")", collapse = "; "),
)

gender_text_qualified <- with(gender_counts |> filter(qualified),
                    paste0(gender, " (", n, ", ", prop, ")", collapse = "; "),
)


```

```{r}
#| label: fig-representative

ethnicity_survey <- intake |> 
  mutate(
    ethnicity = case_match(
      ethnicity,
      c("Other ethnic group", "Others", "Some Other Race alone") ~ "Other",
      "White alone" ~ "White",
      c("Black or African American alone","Black, African, Caribbean or Black British","Black or African American alone") ~ "Black",
      "Native Hawaiian and Other Pacific Islander alone" ~ "Native Hawaiian and Other Pacific Islander",
      "American Indian and Alaska Native alone" ~ "American Indian and Alaska Native",
      c("Asian","Asian alone","Asian or Asian British") ~ "Asian",
      c("Mixed or multiple ethnic groups", "Mixed") ~ "Two or More Races",
      .default = ethnicity
    ),
  ) |> 
  filter(
    !country %in% c("OTHER", NA) & 
      !ethnicity %in% c("Prefer not to say", NA) &
      !(country == "UK" & ethnicity %in% c("American Indian and Alaska Native alone", 
                                           "Native Hawaiian and Other Pacific Islander alone"))
  ) |> 
  group_by(country, ethnicity) %>%
  summarize(
    survey_count = n(),
    gamers_count = sum(!is.na(used_platforms), na.rm = TRUE),
    qualified_count = sum(qualified, na.rm = TRUE),
    survey_moe = 1.96 * sqrt(survey_count * (1 - survey_count / n())) / n(),
    gamers_moe = 1.96 * sqrt(gamers_count * (1 - gamers_count / n())) / n(),
    qualified_moe = 1.96 * sqrt(qualified_count * (1 - qualified_count / n())) / n()
  ) |> 
  group_by(country) |> 
  mutate(
    survey_prop = survey_count / sum(survey_count),
    gamers_prop = gamers_count / sum(gamers_count),
    qualified_prop = qualified_count / sum(qualified_count),
  )

# Join the census and survey summaries
ethnicity_combined <- ethnicity_survey |> 
  ungroup() |> 
  left_join(bind_rows(ethnicity_us, ethnicity_uk), by = c("ethnicity" = "label", "country")) |> 
  pivot_longer(
    cols = c(gen_prop, survey_prop, gamers_prop, qualified_prop),
    names_to = "group",
    values_to = "value"
  ) |> 
  filter(!is.na(value) & !is.na(gen_pop)) |>
  mutate(
    group = recode(group,
                   gen_prop = "General Population",
                   survey_prop = "Screened Participants",
                   gamers_prop = "Self-reported Video Game Players",
                   qualified_prop = "Qualified Participants"
    ),
    group = fct_relevel(group, c("General Population", "Screened Participants", "Self-reported Video Game Players", "Qualified Participants")),
    ethnicity = fct_relevel(ethnicity, c("White", "Black", "Asian", "Two or More Races", "American Indian and Alaska Native", 
                                         "Native Hawaiian and Other Pacific Islander", "Other"))
  )

ggplot(ethnicity_combined, aes(x = group, y = value, fill = ethnicity)) +
  geom_bar(stat = "identity", position = "stack") +
  labs(
    x = "",
    y = "Proportion",
    fill = "Ethnicity",
  ) +
  facet_wrap(~country, scales = "free_x") +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  geom_text(
    aes(
      label = ifelse(value < 0.01, "", scales::label_percent(accuracy = 1)(value)),, 
      family = "serif"
    ), 
    position = position_stack(vjust = 0.5), color = "white") +
  scale_fill_viridis_d(option = "magma", begin = .1, end = .8, labels = function(x) str_wrap(x, width = 25))


```

Our final sample consists of `r nrow(intake[intake$qualified,])`
qualified participants, selected from a pool of `r nrow(intake)`
screened participants. Of the `r nrow(intake[intake$qualified,])` with
recent telemetry, `r nrow(panel)` also completed at least one survey.

Our screening sample was roughly representative of the general
population of the US and UK by ethnicity (@fig-representative) and
gender identity: `r gender_text_all`.

The sample of qualified participants is less representative of the
general population, containing more men and non-binary participants
(`r gender_text_all`), as well as fewer black participants
(@fig-representative)

## Ethics and Compensation

This study received ethical approval from the Social Sciences and
Humanities Inter-Divisional Research Ethics Committee at the University
of Oxford (OII_CIA_23_107). All participants provided informed consent
at the start of the study, including consent to their data being shared
openly for reanalysis.

Prolific participants were paid at a rate of £12/hour for all study
components, which equates to: £0.20 for a 1-minute screening (plus £5
for linking at least one account with recent data), £2 for a 10-minute
intake survey, £0.80 for each 4-minute daily survey, and £2 for each
10-minute biweekly survey. Participants received £10 bonus payments for
completing at least 24 out of 30 daily surveys and/or 5 out of 6
biweekly surveys.

# Deviations from Preregistration

Due to challenges in the recruitment process, we made several deviations
from our preregistration. These changes were made to ensure we could
recruit enough participants to meet our sample size goals and to improve
the quality of the data collected, but in our view do not threaten the
validity of the study. The following deviations were made:

TODO: convert to table

-   After exhausting the PureProfile participant pool, we recruited
    additional participants through the Prolific platform.
-   After exhausting available participants when screening for
    representative samples for ethnicity and gender, we later removed
    quotas and allowed participants from all backgrounds
-   Instead of recruiting participants aged 18--30 in the US and 18--75
    in the UK, we recruited participants in both regions from 18--40.
    This was done because (1) we were unable to recruit enough
    participants in the US aged 18--30, and (2) we wanted results from
    both regions to be comparable.
-   Instead of requiring 75% of total gameplay to take place on the
    platforms included in the study, we instead required 50%
-   Rather than requiring valid play data from the 7-day baseline
    period, we required valid play data from the previous 14-days after
    feedback from participants indicated that play during a 7-day period
    was too easily disrupted by real-world events.
-   Instead of sending surveys at 7pm local time, we sent them at 2pm to
    increase our response rate after feedback from participants
    indicated that evening plans often interfered with survey
    completion.
-   Due to restrictions in the privacy policy of PureProfile, we were
    not able to install third-party apps on users' phones, and therefore
    could not capture Android trace data using ActivityWatch. Instead,
    we used a similar process as iOS by leveraging the Digital Wellbeing
    interface present on many Android models

# Dataset

```{r}
#| label: stack-playtime

# TODO: daily aggregate stacked bar plots
# subplots: self-reported survey data, time use data, telemetry data
# side-by-side stacked bar plot 

sr_pid <- intake |>
  mutate(
    pid,
    qualified,
    self_reported_weekly_play,
    Steam       = self_reported_weekly_play * coalesce(prop_steam/100, 0),
    Xbox        = self_reported_weekly_play * coalesce(prop_xbox/100, 0),
    PlayStation = self_reported_weekly_play * coalesce(prop_playstation/100, 0),
    Nintendo    = self_reported_weekly_play * coalesce(prop_nintendo/100, 0),
    iOS         = self_reported_weekly_play * coalesce(prop_ios/100, 0),
    Android     = self_reported_weekly_play * coalesce(prop_android/100, 0),
    .keep = "none"
  ) |>
  pivot_longer(
    cols = c(Steam, Xbox, PlayStation, Nintendo, iOS, Android),
    names_to = "platform",
    values_to = "minutes"
  ) |> 
  filter(!is.na(minutes))

sr_long <- sr_pid |>
  group_by(qualified, platform) |>
  summarise(minutes = mean(minutes, na.rm = TRUE), .groups = "drop") |>
  mutate(source = "Self-report")

steam_weekly <- steam_sum |>
  filter(timestamp > as.Date("2025-06-01")) |> 
  mutate(week = floor_date(timestamp, "week")) |> 
  group_by(week) |> 
  summarise(
    total_minutes = sum(minutes, na.rm = TRUE),
    minutes_per_player = sum(minutes, na.rm = TRUE) / n_distinct(intake$pid[intake$qualified])
  ) |> 
  summarise(
    minutes = mean(minutes_per_player, na.rm = TRUE)
  ) |> 
  mutate(platform = "Steam", source = "Telemetry")

xbox_weekly <- xbox_clean |> 
  filter(session_start > as.Date("2025-06-01")) |> 
  mutate(week = floor_date(session_start, "week")) |> 
  group_by(week) |> 
  summarise(
    total_minutes = sum(duration, na.rm = TRUE),
    minutes_per_player = sum(duration, na.rm = TRUE) / n_distinct(intake$pid[intake$qualified])
  ) |> 
  summarise(
    minutes = mean(minutes_per_player, na.rm = TRUE)
  ) |> 
  mutate(platform = "Xbox", source = "Telemetry")

xbox_pid <- xbox_clean |> 
  filter(session_start > as.Date("2025-06-01")) |> 
  filter(title_placement == "Full") |> 
  filter(genres != "Video") |> 
  mutate(day = floor_date(session_start, "day")) |> 
  group_by(pid, day) |> 
  summarise(
    total_minutes = sum(duration, na.rm = TRUE))

nintendo_weekly <- nintendo_clean |>
  filter(session_start > as.Date("2025-06-01")) |> 
  mutate(week = floor_date(session_start, "week")) |> 
  group_by(week) |> 
  summarise(
    total_minutes = sum(duration, na.rm = TRUE),
    minutes_per_player = sum(duration, na.rm = TRUE) / n_distinct(intake$pid[intake$qualified])
  ) |> 
  summarise(
    minutes = mean(minutes_per_player, na.rm = TRUE)
  ) |> 
  mutate(platform = "Nintendo", source = "Telemetry")

```

```{r}
#| label: fig-stacked-playtime

# TODO: blur or fuzzy lines? 
# TODO: week-to-week variance? 
# violin plot / side by side - comparison of 5 specific individuals - by quantiles 

weekly_by_platform <-  bind_rows(
    sr_long,
    steam_weekly,
    xbox_weekly,
    nintendo_weekly
  ) |> 
  group_by(source) |> 
  mutate(prop = minutes / sum(minutes)) |> 
  filter(source == "Telemetry" | qualified) |> 
  mutate(platform = fct_reorder(platform, minutes))
  
stack_order <- weekly_by_platform %>%
  filter(source == "Self-report") %>%
  count(platform, wt = minutes, name = "sr") %>%
  arrange(sr) %>% pull(platform)

weekly_by_platform <- weekly_by_platform %>%
  mutate(source = factor(source, levels = c("Self-report","Telemetry")),
         platform = factor(platform, levels = stack_order))

ghost <- weekly_by_platform %>%
  select(platform, source, minutes) %>%
  pivot_wider(names_from = source, values_from = minutes, values_fill = 0) %>%
  mutate(gap = pmax(`Self-report` - Telemetry, 0)) %>%
  arrange(desc(gap)) %>%                                # largest bottom → smallest top
  mutate(
    tele_top = sum(Telemetry, na.rm = TRUE)[1],        # SINGLE anchor = top of Telemetry bar
    ymin     = tele_top + lag(cumsum(gap), default = 0),
    ymax     = ymin + gap,
    xmid     = match("Telemetry", levels(weekly_by_platform$source)),
    xmin     = xmid - 0.9/2,
    xmax     = xmid + 0.9/2,
    ymid     = (ymin + ymax)/2,
    reason = dplyr::case_match(platform, 
                               "iOS" ~ "Missing or low quality screenshots",
                               "PlayStation" ~ "No PlayStation telemetry method",
                               "Android" ~ "Missing or low-quality screenshots",
                               "Nintendo" ~ "Missing 3rd party play",
                               "Steam" ~ "Uncaptured Steam play\n(e.g., invisible mode, account sharing)", .default = NA_character_)
  ) |> 
  filter(gap > 0)

ggplot(weekly_by_platform, aes(x = source, y = minutes, fill = platform)) +
  geom_bar(stat = "identity", position = "stack", width = 0.9) +
  scale_fill_viridis_d(option = "magma", begin = .1, end = .8, limits = stack_order) +
  labs(x = "Data Source", y = "Weekly Playtime (minutes)", fill = "Platform") +
  theme(legend.position = "bottom") +
  geom_text(
    aes(label = ifelse(minutes < 10, "", round(minutes, 0))),
    position = position_stack(vjust = 0.5), color = "white", family = "serif"
  ) +
  # dotted ghost rectangles that fill Telemetry up to Self-report
  geom_rect(
    data = ghost,
    aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax),
    inherit.aes = FALSE, linetype = "dotted", linewidth = 0.6, color = "black", fill = NA
  ) +
  geom_text(
    data = ghost,
    aes(x = xmid, y = ymid, label = paste0("+", round(gap, 0))),
    inherit.aes = FALSE, family = "serif"
  ) +
  # optional arrows + brief reasons (remove if not needed)
  geom_text_repel(
    data = ghost %>% filter(!is.na(reason)),
    aes(x = xmid + .05, y = ymid, label = reason),
    nudge_x = 1, hjust = 1, direction = "y",
    arrow = arrow(length = unit(6, "pt"), type = "closed"),
    min.segment.length = 0, box.padding = 0.25, point.padding = 0.25,
    inherit.aes = FALSE, family = "serif"
  ) +
  coord_cartesian(clip = "off", ylim = c(0, max(ghost$ymax) * 1.08), xlim = c(1, max(ghost$xmax) * 1.08))
```

TODO: single case study plot

## Demographic measures

We collected the following demographic variables:

-   age
-   gender
-   ethnicity
-   educational attainment
-   employment status
-   height
-   weight
-   self-identified neurodivergence (e.g., ASD, ADHD, dyslexia)
-   diagnosed neurodivergence
-   marital status
-   caretaking responsibilities (children, family members)
-   postal geography (general area only; first three digits of the
    five-digit US ZIP Code; UK outward code)

## Self-report measures

### Trait measures

| Construct  | Measure | Example Item |
|:-----------|:--------|:-------------|
| Chronotype |         |              |
|            |         |              |
|            |         |              |

### Daily measures

+----------------+----------------+----------------+----------------+
| Construct      | Measure        | Example Item   | Internal       |
|                |                |                | consistency    |
|                |                |                | (**McDonald's  |
|                |                |                | ω_h)**         |
+:===============+:===============+:===============+:===============+
| Basic          | *Basic         | I was able to  |                |
| psychological  | Psychological  | do things that |                |
| need           | Need           | I really want  |                |
| satisfaction   | Satisfaction   | and value in   |                |
| and            | and            | life.          |                |
| frustration    | Frustration    |                |                |
|                | Scale* [@Che   |                |                |
|                | n              |                |                |
|                | EtAl2015Basic] |                |                |
|                | brief version  |                |                |
|                | @MartelaRy     |                |                |
|                | a              |                |                |
|                | n2024Assessing |                |                |
+----------------+----------------+----------------+----------------+
|                |                |                |                |
+----------------+----------------+----------------+----------------+
|                |                |                |                |
+----------------+----------------+----------------+----------------+

: *Daily self-report measures*

Consensus Sleep Diary (https://doi.org/10.5665/sleep.1642)

Basic Needs in Games Scale (https://doi.org/10.31234/osf.io/4965z7)

Daily Inventory of Stressful Events
(https://doi.org/10.1177/1073191102091006)

Life satisfaction - Cantril Self-anchoring Scale (Cantril, 1965)

Affective valence

### Biweekly measures

### Monthly measures

### Self-reported play

*Social context of play*: Participants reported which types of social
play they engaged in during the last 24 hours (single-player games only,
multiplayer with real-world friends, multiplayer with online-only
friends, multiplayer with strangers). Participants could select more
than one option.

## Digital Trace Data

TODO: distribution across platforms

Digital trace data from games is collected from five platforms: Xbox,
Nintendo Switch, Steam, iOS, and Android. Each platform differs in its
data structure and collection method. On Xbox and Nintendo, we have
*session-level* data, comprised includes the following fields: . On
Steam we have *hourly aggregates* - every hour, how much time people
spent playing each game. On iOS and Android, we have *daily
aggregates* - every day, how much time people spent playing each game.
We describe each platform in more detail below.

### Xbox

Xbox data is comprised of session histories---that is, a record of the
start and end times when a user plays a game on Xbox. Data was provided
via a data-sharing agreement with Microsoft.

<!-- - `user_id`: A unique identifier for the user -->

<!-- - `game_id`: A unique identifier for the game (typically the title) -->

<!-- - `start_time`: The start time of the session -->

<!-- - `end_time`: The end time of the session -->

<!-- - `duration`: The duration of the session in minutes -->

<!-- - `genre`: The genre(s) of the game (e.g., action, strategy, etc.) -->

Due to restrictions in our data-sharing agreement, game titles are
anonymized and only the game ID is provided alongside information about
its genre(s) and age rating. The game ID is a unique identifier for each
game title, allowing us to analyze gameplay without identifying specific
games.

### Nintendo Switch

### Steam

### iOS

### Android

### Discord

## Executive Function

## Time Use

## Data Quality Checks

We implemented a variety of data quality checks.

1.  In each daily and biweekly survey, one item from the BANGS (daily)
    and BPNSFS (biweekly) was duplicated to assess response consistency
    [@MeadeCraig2012identifying]; participants whose responses to the
    two identical items differed by more than one scale point were
    flagged for potential careless responding.
2.  In the telemetry, we use several heuristics to identify potential
    unreliable sessions: sessions beginning or ending in the future
    (indicative of clock manipulation or other errors), sessions longer
    than 12 hours long, and \[TODO: other heuristics\]

## Missingness

# Discussion

We believe this dataset has potential to address a wide variety of
common research questions in the field.

Some of these questions will be addressed in forthcoming registered
reports: specifically, we have plans to test (1) key hypotheses from the
Basic Needs in Games model [@BallouDeterding2024Basic] about how gaming
relates to basic psychological needs over time, (2) the relationship
between late-night gaming and sleep, and (3) the relationship between
playtime in different genres and wellbeing.

Nonetheless, the richness of this data means that researchers can
explore numerous other questions (or, indeed, conduct and compare
alternative analysis approaches to the above questions). To stimulate
ideas, we present a few questions we think the data are well-suited to
answering.

*How do seasons and weather impact playtime?* Because we capture
timestamped play sessions alongside participants’ geographic locations,
researchers can merge in high‐resolution weather and daylight data to
examine how environmental factors causally influence gaming behavior.
Causal inference techniques such as inverse probability weighting can
enable precise estimates of how, when, and how much people play in
response to seasonal and meteorological changes. By quantifying these
effects, researchers can better distinguish weather‐related demand from
other drivers (like work schedules or weekend routines), improving the
precision of studies on gaming’s impact on wellbeing, motivation, and
cognition.

*How do neurotypical and neurodiverse players differ in their gaming
behavior?* Using the neurodivergence data we collected (which includes,
for example, `r table(intake$neuroIdenCondition_1)[1]` participants who
identify as having autism and `r table(intake$neuroIdenCondition_2)[1]`
who identify as having ADHD), researchers can. Neurodiversity in games
has regularly been studied in the context of specific games and with
qualitative methods

Self-reported play accuracy - inference from other papers

## Future Work

The trace data presented here is wide-ranging, but shallow—we capture
all gaming that happens on a particular platform or set of platforms,
but have no insight into what the player is doing in-game. With previous
work and theory clear that in-game behavior (e.g., what character role a
player adopts) and experiences (e.g., performance in competitive modes)
are key features of games' wellbeing impacts,

There is an inherent trade-off between breadth (how widely telemetry can
be captured) and depth (the level of detail about in-game behaviours).
At present, we areWe see strong potential in study designs that capture
platform-level contextual data, combined with

## Data Availability

All data, materials, and code related to this dataset are available on
the Open Science Framework \[TODO: LINK\], and the data is archived on
Zenodo \[TODO: LINK\].